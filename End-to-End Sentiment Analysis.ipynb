{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7cd94cf",
   "metadata": {},
   "source": [
    "# End-to-End Sentiment Analysis\n",
    "### Using neural models to predict sentiment on Amazon reivews\n",
    "As an end-to-end model, we will be covering:\n",
    "1) Data collection\n",
    "2) Exploratory data analysis\n",
    "3) Data processing and preparation\n",
    "4) Building the models\n",
    "5) Selecting a model using cross-validation\n",
    "6) Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc4372",
   "metadata": {},
   "source": [
    "#### Data Collection\n",
    "Load libraries used for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2997d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee60081",
   "metadata": {},
   "source": [
    "We will be using the Amazon reviews dataset from Kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3145e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Amazon reviews dataset\n",
    "amazon_df = pd.read_csv('amazon_alexa.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3432c1e",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis\n",
    "Check the data for null values, value distributions, datatypes, and shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23057f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon dataframe columns: ['rating' 'date' 'variation' 'verified_reviews' 'feedback']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   rating            3150 non-null   int64 \n",
      " 1   date              3150 non-null   object\n",
      " 2   variation         3150 non-null   object\n",
      " 3   verified_reviews  3150 non-null   object\n",
      " 4   feedback          3150 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 123.2+ KB\n",
      "Data info: None\n",
      "Amazon dataframe shape: (3150, 5)\n",
      "   rating       date         variation  \\\n",
      "0       5  31-Jul-18  Charcoal Fabric    \n",
      "1       5  31-Jul-18  Charcoal Fabric    \n",
      "2       4  31-Jul-18    Walnut Finish    \n",
      "3       5  31-Jul-18  Charcoal Fabric    \n",
      "4       5  31-Jul-18  Charcoal Fabric    \n",
      "\n",
      "                                    verified_reviews  feedback  \n",
      "0                                      Love my Echo!         1  \n",
      "1                                          Loved it!         1  \n",
      "2  Sometimes while playing a game, you can answer...         1  \n",
      "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
      "4                                              Music         1  \n"
     ]
    }
   ],
   "source": [
    "print(f'Amazon dataframe columns: {amazon_df.columns.values}')\n",
    "print(f'Data info: {amazon_df.info()}')\n",
    "print(f'Amazon dataframe shape: {amazon_df.shape}')\n",
    "print(amazon_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "375e3d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating              0\n",
      "date                0\n",
      "variation           0\n",
      "verified_reviews    0\n",
      "feedback            0\n",
      "dtype: int64\n",
      "Label distribution:\n",
      "1    0.918413\n",
      "0    0.081587\n",
      "Name: feedback, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(amazon_df.isnull().sum())\n",
    "\n",
    "# Check the distribution in the feedback column\n",
    "label_dist = amazon_df['feedback'].value_counts()/len(amazon_df)\n",
    "print('Label distribution:')\n",
    "print(label_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d9944",
   "metadata": {},
   "source": [
    "There are no null values however, the data is extremely imbalanced if we use feedback as our labels. We will likely have to disregard the results since it would be difficult to do better than the Zero Rule Algorithm.\n",
    "\n",
    "That is, our model has to score better than a random algorithm which has an expected value of 91% due to the imbalanced distribution.\n",
    "\n",
    "One way we can work around this is to use the ratings and decide how many stars dictate a positive rating. Let's take a look at the distribution of the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babdfe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating distribution:\n",
      "5    0.725714\n",
      "4    0.144444\n",
      "1    0.051111\n",
      "3    0.048254\n",
      "2    0.030476\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rating_dist = amazon_df['rating'].value_counts()/len(amazon_df)\n",
    "print('Rating distribution:')\n",
    "print(rating_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cc83f",
   "metadata": {},
   "source": [
    "The distribution shows that in order to create a more balance dataset, we would have to classify 4 stars and lower as negative. However, that would be counter-intuitive as many 4 star ratings are also generally positive. \n",
    "\n",
    "This kind of split would lower the accuracy of our model and push it towards a classifer between extremely positive and others, rather than positive and negative. For this reason, we should not use this dataset for any real insight on sentiment anaylsis. There will be another sentiment analysis using Twitter feeds in my repository.\n",
    "\n",
    "For now, we will complete the model as though the dataset was okay just for the sake of building an end-to-end project. This is why data exploration is imperative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ef9d5",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "We want to clean up the reviews by removing stopwords (common words like 'the' that don't add much meaning), numbers, and symbols, and keep only words. Then we will give the words corresponding numbers by tokenizing them for our neural network to learn dependencies via an Embedding layer. \n",
    "\n",
    "It helps us to automate the data processing and machine learning workflow by utitlizing pipelines in our program. Pipelines also allow for better scalablity for our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45a1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d33e1e",
   "metadata": {},
   "source": [
    "To use a pipeline for data transformation, we will develop custom classes that will remove stopwords, clean up numbers and symbols and one that will tokenize the reviews. \n",
    "\n",
    "Our tokenizer needs a vocabulary size and we also have to define a constant length of the words so it can be put into our neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8fb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class transformer to clean up the reviews\n",
    "class ReviewPrep(TransformerMixin):\n",
    "    def __init__(self, stopwords):\n",
    "        self.stopwords = stopwords # Removing stopwords requires a new variable\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X['verified_reviews'] = X['verified_reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in (self.stopwords)])) # reviews are idx = 3\n",
    "        X['verified_reviews'] = X['verified_reviews'].apply(lambda x: re.sub('[^a-zA-Z\\s]', '',x)) # Keep only letters\n",
    "        return X\n",
    "\n",
    "class TokenReview(TransformerMixin):\n",
    "    def __init__(self, vocab, max_words):\n",
    "        self.vocab = vocab\n",
    "        self.max_words = max_words\n",
    "        self.tokenizer = Tokenizer(num_words = self.vocab, split=' ', filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "    def fit(self, X, y=None):\n",
    "        self.tokenizer.fit_on_texts(X['verified_reviews'])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X['verified_reviews'] = self.tokenizer.texts_to_sequences(X['verified_reviews'])\n",
    "        X['verified_reviews'] = pad_sequences(X['verified_reviews'], padding='post', maxlen=max_words)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cf88e9",
   "metadata": {},
   "source": [
    "Now we use our custom transformers to setup a pipeline for the transformations on the review column. \n",
    "\n",
    "We also build another pipeline to process all of the data. \n",
    "\n",
    "This kind of modularity is useful should we ever want to build another pipeline that performs a different set of transfromations on the numerical data columns, then we could integrate that pipeline into our overarching pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef0df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def review_pipeline(stopwords, vocab, max_words):\n",
    "    \"\"\"\n",
    "    Pipeline to prep the reviews and tokenize them\n",
    "\n",
    "    Arguments:\n",
    "        stopwords: stopwords to remove with ReviewPrep\n",
    "        vocab: Vocab size for tokenizer\n",
    "        max_words: max word length for padding\n",
    "    Returns:\n",
    "        text_pipeline: pipeline object of transformations for reviews\n",
    "    \"\"\"\n",
    "\n",
    "    text_pipeline = Pipeline([\n",
    "        ('cleanup', ReviewPrep(stopwords)),\n",
    "        ('tokenize', TokenReview(vocab, max_words))\n",
    "        ])\n",
    "    return text_pipeline\n",
    "\n",
    "def full_pipeline(data, stopwords, vocab, max_words):\n",
    "    \"\"\"\n",
    "    Transformation pipeline for the data\n",
    "\n",
    "    Arguments:\n",
    "        data: original data\n",
    "    Returns:\n",
    "        prepped_data: fully transformed review data\n",
    "        prepped_labels: review labels\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    all_transformers = ColumnTransformer([\n",
    "        ('prep_rev', review_pipeline(stopwords, vocab, max_words), ['verified_reviews'])\n",
    "        ])\n",
    "\n",
    "    prepped_reviews = all_transformers.fit_transform(data)\n",
    "    prepped_labels = data['feedback'].to_numpy()\n",
    "    \n",
    "    return prepped_reviews, prepped_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5c035",
   "metadata": {},
   "source": [
    "Now that we have the classes and definitions that we need, we will set the variables and call the pipeline to process our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aab2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stopwords to remove common but not useful words for analysis such as 'the', 'an'\n",
    "stopwords = set(stopwords.words('english'))\n",
    "vocab = 500 # The first x most used words aka vocab size\n",
    "max_words = 20 # Max number of words in text (in order for Dense layer to connect to Embedding layer)\n",
    "embedding_dim = 5 # Dimensions of vector to represent word in embedding layer\n",
    "\n",
    "# Call the pipeline on the original dataset\n",
    "prepped_reviews, prepped_labels = full_pipeline(amazon_df, stopwords, vocab, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abbf0c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepped reviews sequence shape: (3150, 20)\n",
      "Prepped labels shape: (3150,)\n",
      "Prepped data: [[  2   4   0 ...   0   0   0]\n",
      " [203   3   0 ...   0   0   0]\n",
      " [231 112 265 ...   0   0   0]\n",
      " ...\n",
      " [151  46  41 ...  96  50  34]\n",
      " [ 93  16 487 ... 124 126 118]\n",
      " [ 17   0   0 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Quick check to see everything working\n",
    "print(f'Prepped reviews sequence shape: {prepped_reviews.shape}')\n",
    "print(f'Prepped labels shape: {prepped_labels.shape}')\n",
    "print(f'Prepped data: {prepped_reviews}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740fca1",
   "metadata": {},
   "source": [
    "Our training data and our training labels have equal number of samples and the words are now numbers that correspond to a word in our tokenizer dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f6553",
   "metadata": {},
   "source": [
    "#### Building the models\n",
    "We will only build one simple RNN model (using an LSTM layer) since we are not looking to use this data due to the dataset issue stated earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7006bb",
   "metadata": {},
   "source": [
    "We will be using a gridsearch and a cross validation function from sklearn in the next section. In order to do so, we need to create a function that will build our model so we can use a KerasClassifier wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23bde9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b52b27e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 20, 5)             2500      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 20)                2080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,601\n",
      "Trainable params: 4,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build a LSTM model\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, Input, Flatten\n",
    "\n",
    "def build_LSTM(vocab=200, max_words=20, embedding_dim=8, neurons=20):\n",
    "    \"\"\"\n",
    "    Builds an LSTM model for analysis\n",
    "\n",
    "    Arguments:\n",
    "        None\n",
    "    Returns:\n",
    "        model: an LSTM model\n",
    "    \"\"\"\n",
    "\n",
    "    input_layer = Input(shape=(max_words))\n",
    "    x = Embedding(vocab, embedding_dim, input_length=max_words)(input_layer) # Converts positive integer encoding of words as vectors into dimensional space where similiarity in meaning is represented by closeness in space\n",
    "    x = LSTM(neurons, dropout=0.1)(x)# Stacked LSTM potentially allows the hidden state to operate at different time scales\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(input_layer, out)\n",
    "\n",
    "    model.compile(\n",
    "    loss ='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics='acc'\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Let's check out our model\n",
    "LSTM_model = build_LSTM(vocab=vocab, max_words=max_words, embedding_dim=embedding_dim)\n",
    "print(LSTM_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f342e",
   "metadata": {},
   "source": [
    "#### Select the model with cross-validation\n",
    "In order to properly evaluate the model, we have to designate certain samples to be held-out of the training set into the test set.\n",
    "\n",
    "We will then use cross-validation on the training set to get an average of our model's performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39415908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and held-out test sets with stratified sampling so we better represent the data's proportions\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 33\n",
    "np.random.seed(seed)\n",
    "\n",
    "s_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed) # Using a random seed here for the Grid Search \n",
    "\n",
    "for train_idx, test_idx in s_split.split(prepped_reviews, prepped_labels):\n",
    "    train_set = prepped_reviews[train_idx]\n",
    "    train_labels = prepped_labels[train_idx]\n",
    "    test_set = prepped_reviews[test_idx]\n",
    "    test_labels = prepped_labels[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404057d",
   "metadata": {},
   "source": [
    "For our cross-validation from sklearn to work, we have to use a wrapper called KerasClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d248a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "BATCH = 64\n",
    "EPOCHS = 1 # Temporarily due to my slow computer\n",
    "\n",
    "LSTM_wrapped = KerasClassifier(\n",
    "    model=build_LSTM,\n",
    "    neurons = 20,\n",
    "    vocab = vocab,\n",
    "    max_words = max_words,\n",
    "    embedding_dim = embedding_dim,\n",
    "    batch_size = BATCH,\n",
    "    epochs = EPOCHS,\n",
    "    random_state = seed,\n",
    "    optimizer = 'adam',\n",
    "    verbose = 0\n",
    "    )\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cv_scores(model, train_set, train_labels):\n",
    "    \"\"\"\n",
    "    Evaluate score by cross-validation\n",
    "\n",
    "    Arguments:\n",
    "        model: neural network model\n",
    "        train_set: training set\n",
    "    Returns:\n",
    "        scores: an array of scores for each run\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        train_set,\n",
    "        train_labels,\n",
    "        scoring = 'accuracy',\n",
    "        cv = 10\n",
    "        )\n",
    "\n",
    "    print(f'This is the average score of the cv: {scores.mean()}')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a9776",
   "metadata": {},
   "source": [
    "Now we pass in the training set and training labels to see how our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cffb4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the average score of the cv: 0.9182539682539682\n",
      "CV Score for LSTM:\n",
      "[0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n",
      " 0.92063492 0.92063492 0.92063492 0.92063492]\n"
     ]
    }
   ],
   "source": [
    "LSTM_scores = cv_scores(LSTM_wrapped, train_set, train_labels)\n",
    "print('CV Score for LSTM:')\n",
    "print(LSTM_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4c1f7",
   "metadata": {},
   "source": [
    "The average score for our model did not perform better than the Zero Rule with the expected value of 0.9184. This was expected since our dataset was so heavily imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93aac9",
   "metadata": {},
   "source": [
    "#### Hyperparameters Tuning\n",
    "We will still go ahead and finish building the end-to-end machine learning program for completeness but we cannot expect any improvement using our flawed dataset.\n",
    "\n",
    "For hyperparameters tuning, we will use GridSearchCV from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e89a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 5, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 5, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 5, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 10, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 10, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 10, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 15, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 15, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 15, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 20, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 20, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 5, 'neurons': 20, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 5, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 5, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 5, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 10, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 10, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 10, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 15, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 15, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 15, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 20, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 20, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 8, 'neurons': 20, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 5, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 5, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 5, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 10, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 10, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 10, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 15, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 15, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 15, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 20, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 20, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 10, 'neurons': 20, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 5, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 5, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 5, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 10, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 10, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 10, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 15, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 15, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 15, 'vocab': 2000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 20, 'vocab': 500}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 20, 'vocab': 1000}\n",
      "Mean: 0.9182539682539682 with {'embedding_dim': 12, 'neurons': 20, 'vocab': 2000}\n",
      "Best score is: 0.9182539682539682\n",
      "Best params is: {'embedding_dim': 5, 'neurons': 5, 'vocab': 500}\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETER TUNING\n",
    "# Now that we've chosen the best model, we'll tune the hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = [{\n",
    "    'neurons' : [5, 10, 15, 20],\n",
    "    'vocab': [500, 1000, 2000],\n",
    "    'embedding_dim' : [5, 8, 10, 12]\n",
    "    }]\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LSTM_wrapped,\n",
    "    param_grid=param_grid,\n",
    "    scoring = 'accuracy', # defaults to accuracy\n",
    "    n_jobs = -1, # -1 means it'll use all the cores in the computer\n",
    "    cv = 3 # defaults to 3\n",
    "    )\n",
    "\n",
    "grid_results = grid.fit(train_set, train_labels)\n",
    "\n",
    "cv_scores = grid_results.cv_results_\n",
    "for mean, params in zip(cv_scores['mean_test_score'],cv_scores['params']):\n",
    "    print(f'Mean: {mean} with {params}')\n",
    "\n",
    "print(f'Best score is: {grid_results.best_score_}')\n",
    "print(f'Best params is: {grid_results.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657e029",
   "metadata": {},
   "source": [
    "#### Evaluating the final model\n",
    "Now that we've (theoretically) chosen the right model and the optimal hyperparameters, we will use our held-out test set to evaluate it's performance.\n",
    "\n",
    "*Note that our flawed data gave the same estimate for the gridsearch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70c995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the test accuracy: 0.919047619047619\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE FINAL MODEL WITH HELD OUT TEST SET\n",
    "# Best configuration\n",
    "final_model = grid_results.best_estimator_\n",
    "\n",
    "# Final evaluation\n",
    "final_pred = final_model.predict(\n",
    "    test_set\n",
    "    )\n",
    "\n",
    "final_acc = np.mean(test_labels == final_pred)\n",
    "\n",
    "print(f'This is the test accuracy: {final_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
